{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/stumbleupon/test.tsv\n/kaggle/input/stumbleupon/train.tsv\n/kaggle/input/stumbleupon/sampleSubmission.csv\n/kaggle/input/stumbleupon/raw_content.zip\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom nltk.stem import PorterStemmer\nimport re\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom sklearn.model_selection import train_test_split\nimport plotly.express as px\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking all columns of training set only for data exploration\ndf_train=pd.read_csv('../input/stumbleupon/train.tsv',sep='\\t')\n\n# taking boilerplate column as an input for the model beacuse only this column contain lot of high quality text data useful for our nlp task\ndf_test=pd.read_csv('../input/stumbleupon/test.tsv',sep='\\t')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=df_train.dropna()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.reset_index(inplace=True)\ndf_train.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(7395, 28)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['boilerplate'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"varValue = df_train.label.value_counts()\nprint(varValue)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['label'].value_counts().plot(kind='pie',colors=['#2C4373', '#F2A74B'],autopct='%1.1f%%',figsize=(9,9))\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['alchemy_category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.countplot(x=df_train['alchemy_category'],hue=df_train['label']);\nplt.xlabel('Category');\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data=df_train.drop(['url', 'urlid', 'boilerplate','alchemy_category','framebased','hasDomainLink','is_news','lengthyLinkDomain','news_front_page'],axis=1)\n\nX = x_data.drop(\"label\",1)\ny = x_data[\"label\"]\nx_data.head()\nplt.figure(figsize=(15,7))\ncor = x_data.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()\n\ncor_target = abs(cor[\"label\"]) #absolute value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"relevant_features = cor_target[cor_target>=0.1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\ntitle=[]\nbody=[]\nlabel=[]\nalchemy_category_score=[]\nurlid=[]\nurl=[]\nlinkwordscore=[]\nframeTagRatio =[]\ncommonlinkratio_3    =[]\nfor i in range(7395):\n    X=json.loads(df_train[\"boilerplate\"][i])\n    if 'title' in X.keys() and 'body' in X.keys() and 'url' in X.keys():\n        title.append(X.get('title'))\n        body.append(X.get('body'))\n        url.append(X.get('url'))\n        label.append(df_train['label'][i])\n        alchemy_category_score.append(df_train['alchemy_category_score'][i])\n        urlid.append(df_train['urlid'][i])\n        linkwordscore.append(df_train['linkwordscore'][i])\n        frameTagRatio.append(df_train['frameTagRatio'][i])\n        commonlinkratio_3.append(df_train['commonlinkratio_3'][i])\n    \n\ndict_df = {'urlid':urlid,'title':title,'body':body,'url':url,'linkwordscore':linkwordscore,'frameTagRatio':frameTagRatio,'alchemy_category_score':alchemy_category_score,'commonlinkratio_3':commonlinkratio_3,'label':label}\ndata_df = pd.DataFrame.from_dict(dict_df)\n\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['body'].isnull().value_counts()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"False    7278\nTrue       57\nName: body, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df=data_df.dropna()\ndata_df.reset_index(inplace=True,drop=True)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['body'].isnull().value_counts()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"False    7267\nName: body, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\ntitle=[]\nbody=[]\nalchemy_category_score=[]\nurlid=[]\nurl=[]\nlinkwordscore=[]\nframeTagRatio =[]\ncommonlinkratio_3    =[]\n\nfor i in range(len(df_test)):\n    X=json.loads(df_test[\"boilerplate\"][i])\n    if 'title' in X.keys() and 'body' in X.keys() and 'url'in X.keys():\n        title.append(X.get('title'))\n        body.append(X.get('body'))\n        url.append(X.get('url'))\n        alchemy_category_score.append(df_test['alchemy_category_score'][i])\n        urlid.append(df_test['urlid'][i])\n        linkwordscore.append(df_test['linkwordscore'][i])\n        frameTagRatio.append(df_test['frameTagRatio'][i])\n        commonlinkratio_3.append(df_test['commonlinkratio_3'][i])\n\ndict_df = {'urlid':urlid,'title':title,'body':body,'url':url,'linkwordscore':linkwordscore,'frameTagRatio':frameTagRatio,'alchemy_category_score':alchemy_category_score,'commonlinkratio_3':commonlinkratio_3}\ntest_df = pd.DataFrame.from_dict(dict_df)\n\ntest_df=test_df.dropna()\ntest_df.reset_index(inplace=True)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data_df.drop('label',axis=1).values### independent features\ny=data_df['label'].values###dependent features","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['alchemy_category_score'].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\n\nnltk.download('stopwords')\n\n","execution_count":10,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(data_df)):\n    \n    content = re.sub('[^a-zA-Z]', ' ', data_df['body'][i])\n    content = content.lower()\n    content = content.split()\n    \n    content = [ps.stem(word) for word in content if not word in stopwords.words('english')]\n    content = ' '.join(content)\n    corpus.append(content)\nprint('end')","execution_count":11,"outputs":[{"output_type":"stream","text":"end\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['title'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(corpus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocabulary = set()\nfor corpu in corpus:\n        if corpu not in vocabulary:\n            vocabulary.add(corpu)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_length = len(vocabulary)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_seq_length = 0\n\nfor title in corpus:\n    if len(title) > max_seq_length:\n        max_seq_length = len(title)\n","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Vocab length:\", vocab_length)\nprint(\"Max sequence length:\", max_seq_length)","execution_count":15,"outputs":[{"output_type":"stream","text":"Vocab length: 6539\nMax sequence length: 21816\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_repr=[one_hot(words,vocab_length)for words in corpus] ","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nembedded_docs = pad_sequences(onehot_repr, maxlen=300)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedded_docs[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,data_df.shape[0]):\n    if(data_df['alchemy_category_score'][i] == '?'):\n        data_df['alchemy_category_score'][i]= '0'\n        \ndata_df['alchemy_category_score'] = data_df['alchemy_category_score'].astype(float)","execution_count":18,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean1=0;\nmean2=0;\nc1=0;\nc2=0;\nfor i in range(0,len(data_df['alchemy_category_score'])):\n    if(data_df['label'][i]==0):\n        mean1=mean1+float(data_df['alchemy_category_score'][i])\n        c1=c1+1\n    if(data_df['label'][i]==1):\n        mean2=mean2+float(data_df['alchemy_category_score'][i])\n        c2=c2+1\nmean2=mean2/c2\nmean1=mean1/c1\n    ","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(data_df['alchemy_category_score'])):\n    if(data_df['alchemy_category_score'][i]==0 &data_df['label'][i]==0):\n        data_df['alchemy_category_score'][i]=mean1\n    if(data_df['alchemy_category_score'][i]==0 &data_df['label'][i]==1):\n         data_df['alchemy_category_score'][i]=mean2","execution_count":20,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp1 = np.array(data_df['alchemy_category_score'].values.tolist())\nprint(\"shape before = \",temp1.shape)\ntemp1 = np.reshape(temp1,(-1,1))\nprint(\"shape after = \",temp1.shape)\n\ntemp2= np.array(data_df['linkwordscore'].values.tolist())\ntemp2 = np.reshape(temp2,(-1,1))\n\ntemp3= np.array(data_df['frameTagRatio'].values.tolist())\ntemp3 = np.reshape(temp3,(-1,1))\n\n\ntemp4= np.array(data_df['commonlinkratio_3'].values.tolist())\ntemp4 = np.reshape(temp4,(-1,1))\n","execution_count":21,"outputs":[{"output_type":"stream","text":"shape before =  (7267,)\nshape after =  (7267, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nseq_len = 300  \n\nz_final=temp2\n\ny_final=np.array(y)\nX_train,X_test,y_train,y_test,z_train,z_test=train_test_split(embedded_docs,y_final,z_final,test_size=0.25,random_state=0)\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn as nn\n\ntrain_data = TensorDataset(torch.from_numpy(X_train),torch.from_numpy(z_train), torch.from_numpy(y_train))\nval_data = TensorDataset(torch.from_numpy(X_test),torch.from_numpy(z_test), torch.from_numpy(y_test))\n\nbatch_size = 300\n\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nval_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)","execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'temp2' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e4454f28b202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mz_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'temp2' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class lstm_model(nn.Module):\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n        super(lstm_model, self).__init__()\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob)\n        self.dropout = nn.Dropout(drop_prob)\n        self.fc = nn.Linear(hidden_dim, output_size)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x,f2,hidden):\n        batch_size = x.size(0)\n        x = x.long()\n        embeds = self.embedding(x)\n        lstm_out, hidden = self.lstm(embeds,hidden)\n     \n        out=torch.cat([lstm_out,f2])\n        out = self.dropout(lstm_out)\n        \n        out = self.fc(out)\n        out = self.sigmoid(out)\n        \n        out = out.view(batch_size, -1)\n        out = out[:,-1]\n        return out, hidden\n\n    def init_hidden(self, batch_size):\n        weight = next(self.parameters()).data\n        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n        return hidden","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = vocab_length + 1\noutput_size = 1\nembedding_dim = 300\nhidden_dim = 512\nn_layers = 2\n\nmodel = lstm_model(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\nlr=0.005\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)","execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'vocab_length' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-e27adc29b2eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'vocab_length' is not defined"]}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":" for inputs1,inputs2, labels in train_loader:\n        print(inputs1.shape)\n        print(inputs2.shape)\n        print(labels.shape)","execution_count":34,"outputs":[{"output_type":"stream","text":"torch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([250, 300])\ntorch.Size([250, 1])\ntorch.Size([250])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score\nimport time\nstart_time=time.time()\nepochs=1000\nfinal_losses=[]\nfor i in range(epochs):\n    i=i+1\n    for i in range(epochs):\n        hidden = model.init_hidden(batch_size)\n    \n        for inputs1,inputs2, labels in train_loader:\n            y_pred=model.forward(inputs1,inputs2,hidden)\n            loss=loss_function(y_pred,y_train)\n            final_losses.append(loss)\n            if i%10==1:\n                print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n            otimizer.zero_grad()\n            loss.backward()\n            otimizer.step()\nprint(time.time()-start_time)","execution_count":25,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Expected hidden[0] size (2, 300, 512), got [2, 400, 512]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-94c5bc297d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mfinal_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-e0ff4977017c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, f2, hidden)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0;32m--> 534\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    535\u001b[0m         self.check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[1;32m    536\u001b[0m                                'Expected hidden[1] size {}, got {}')\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    194\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 300, 512), got [2, 400, 512]"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## loss function\nimport matplotlib.pyplot as plt\n\nplt.plot(range(epochs),final_losses)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\n#### Prediction in X_test data\npredictions=[]\nwith torch.no_grad():\n    hidden = model.init_hidden(batch_size)\n    for inputs1,inputs2, labels in val_loader:\n        y_pred=model(inputs1,inputs2,hidden)\n        predictions.append(y_pred.argmax().item())\n        print(y_pred.argmax().item())\n\nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,predictions)\ncm\nplt.figure(figsize=(10,6))\nsns.heatmap(cm,annot=True)\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,predictions)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\nrecall_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\nprecision_score(y_test,predictions)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}