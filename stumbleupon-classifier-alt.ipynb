{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/stumbleupon/test.tsv\n/kaggle/input/stumbleupon/train.tsv\n/kaggle/input/stumbleupon/sampleSubmission.csv\n/kaggle/input/stumbleupon/raw_content.zip\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom nltk.stem import PorterStemmer\nimport re\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom sklearn.model_selection import train_test_split\nimport plotly.express as px\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking all columns of training set only for data exploration\ndf_train=pd.read_csv('../input/stumbleupon/train.tsv',sep='\\t')\n\n# taking boilerplate column as an input for the model beacuse only this column contain lot of high quality text data useful for our nlp task\ndf_test=pd.read_csv('../input/stumbleupon/test.tsv',sep='\\t')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=df_train.dropna()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.reset_index(inplace=True)\ndf_train.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(7395, 28)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['boilerplate'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"varValue = df_train.label.value_counts()\nprint(varValue)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['label'].value_counts().plot(kind='pie',colors=['#2C4373', '#F2A74B'],autopct='%1.1f%%',figsize=(9,9))\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['alchemy_category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.countplot(x=df_train['alchemy_category'],hue=df_train['label']);\nplt.xlabel('Category');\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data=df_train.drop(['url', 'urlid', 'boilerplate','alchemy_category','framebased','hasDomainLink','is_news','lengthyLinkDomain','news_front_page'],axis=1)\n\nX = x_data.drop(\"label\",1)\ny = x_data[\"label\"]\nx_data.head()\nplt.figure(figsize=(15,7))\ncor = x_data.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()\n\ncor_target = abs(cor[\"label\"]) #absolute value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"relevant_features = cor_target[cor_target>=0.1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\ntitle=[]\nbody=[]\nlabel=[]\nalchemy_category_score=[]\nurlid=[]\nurl=[]\nlinkwordscore=[]\nframeTagRatio =[]\ncommonlinkratio_3    =[]\nfor i in range(7395):\n    X=json.loads(df_train[\"boilerplate\"][i])\n    if 'title' in X.keys() and 'body' in X.keys() and 'url' in X.keys():\n        title.append(X.get('title'))\n        body.append(X.get('body'))\n        url.append(X.get('url'))\n        label.append(df_train['label'][i])\n        alchemy_category_score.append(df_train['alchemy_category_score'][i])\n        urlid.append(df_train['urlid'][i])\n        linkwordscore.append(df_train['linkwordscore'][i])\n        frameTagRatio.append(df_train['frameTagRatio'][i])\n        commonlinkratio_3.append(df_train['commonlinkratio_3'][i])\n    \n\ndict_df = {'urlid':urlid,'title':title,'body':body,'url':url,'linkwordscore':linkwordscore,'frameTagRatio':frameTagRatio,'alchemy_category_score':alchemy_category_score,'commonlinkratio_3':commonlinkratio_3,'label':label}\ndata_df = pd.DataFrame.from_dict(dict_df)\n\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['body'].isnull().value_counts()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"False    7278\nTrue       57\nName: body, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df=data_df.dropna()\ndata_df.reset_index(inplace=True,drop=True)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['body'].isnull().value_counts()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"False    7267\nName: body, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\ntitle=[]\nbody=[]\nalchemy_category_score=[]\nurlid=[]\nurl=[]\nlinkwordscore=[]\nframeTagRatio =[]\ncommonlinkratio_3    =[]\n\nfor i in range(len(df_test)):\n    X=json.loads(df_test[\"boilerplate\"][i])\n    if 'title' in X.keys() and 'body' in X.keys() and 'url'in X.keys():\n        title.append(X.get('title'))\n        body.append(X.get('body'))\n        url.append(X.get('url'))\n        alchemy_category_score.append(df_test['alchemy_category_score'][i])\n        urlid.append(df_test['urlid'][i])\n        linkwordscore.append(df_test['linkwordscore'][i])\n        frameTagRatio.append(df_test['frameTagRatio'][i])\n        commonlinkratio_3.append(df_test['commonlinkratio_3'][i])\n\ndict_df = {'urlid':urlid,'title':title,'body':body,'url':url,'linkwordscore':linkwordscore,'frameTagRatio':frameTagRatio,'alchemy_category_score':alchemy_category_score,'commonlinkratio_3':commonlinkratio_3}\ntest_df = pd.DataFrame.from_dict(dict_df)\n\ntest_df=test_df.dropna()\ntest_df.reset_index(inplace=True)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data_df.drop('label',axis=1).values### independent features\ny=data_df['label'].values###dependent features","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['alchemy_category_score'].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\n\nnltk.download('stopwords')\n\n","execution_count":10,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(data_df)):\n    \n    content = re.sub('[^a-zA-Z]', ' ', data_df['body'][i])\n    content = content.lower()\n    content = content.split()\n    \n    content = [ps.stem(word) for word in content if not word in stopwords.words('english')]\n    content = ' '.join(content)\n    corpus.append(content)\nprint('end')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['title'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(corpus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocabulary = set()\nfor corpu in corpus:\n        if corpu not in vocabulary:\n            vocabulary.add(corpu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_length = len(vocabulary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_seq_length = 0\n\nfor title in corpus:\n    if len(title) > max_seq_length:\n        max_seq_length = len(title)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Vocab length:\", vocab_length)\nprint(\"Max sequence length:\", max_seq_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_repr=[one_hot(words,vocab_length)for words in corpus] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nembedded_docs = pad_sequences(onehot_repr, maxlen=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedded_docs[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,data_df.shape[0]):\n    if(data_df['alchemy_category_score'][i] == '?'):\n        data_df['alchemy_category_score'][i]= '0'\n        \ndata_df['alchemy_category_score'] = data_df['alchemy_category_score'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean1=0;\nmean2=0;\nc1=0;\nc2=0;\nfor i in range(0,len(data_df['alchemy_category_score'])):\n    if(data_df['label'][i]==0):\n        mean1=mean1+float(data_df['alchemy_category_score'][i])\n        c1=c1+1\n    if(data_df['label'][i]==1):\n        mean2=mean2+float(data_df['alchemy_category_score'][i])\n        c2=c2+1\nmean2=mean2/c2\nmean1=mean1/c1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(data_df['alchemy_category_score'])):\n    if(data_df['alchemy_category_score'][i]==0 &data_df['label'][i]==0):\n        data_df['alchemy_category_score'][i]=mean1\n    if(data_df['alchemy_category_score'][i]==0 &data_df['label'][i]==1):\n         data_df['alchemy_category_score'][i]=mean2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp1 = np.array(data_df['alchemy_category_score'].values.tolist())\nprint(\"shape before = \",temp1.shape)\ntemp1 = np.reshape(temp1,(-1,1))\nprint(\"shape after = \",temp1.shape)\n\ntemp2= np.array(data_df['linkwordscore'].values.tolist())\ntemp2 = np.reshape(temp2,(-1,1))\n\ntemp3= np.array(data_df['frameTagRatio'].values.tolist())\ntemp3 = np.reshape(temp3,(-1,1))\n\n\ntemp4= np.array(data_df['commonlinkratio_3'].values.tolist())\ntemp4 = np.reshape(temp4,(-1,1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nseq_len = 300  # The length that the sentences will be padded/shortened to\n\nz_final=temp2\n# Converting our labels into numpy arrays\ny_final=np.array(y)\nX_train,X_test,y_train,y_test,z_train,z_test=train_test_split(embedded_docs,y_final,z_final,test_size=0.25,random_state=0)\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn as nn\n\ntrain_data = TensorDataset(torch.from_numpy(X_train),torch.from_numpy(z_train), torch.from_numpy(y_train))\nval_data = TensorDataset(torch.from_numpy(X_test),torch.from_numpy(z_test), torch.from_numpy(y_test))\n\nbatch_size = 400\n\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nval_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class lstm_model(nn.Module):\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n        super(lstm_model, self).__init__()\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob)\n        self.dropout = nn.Dropout(drop_prob)\n        self.fc = nn.Linear(hidden_dim, output_size)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x,f2,hidden):\n        batch_size = x.size(0)\n        x = x.long()\n        embeds = self.embedding(x)\n        lstm_out, hidden = self.lstm(embeds,hidden)\n     \n        out=torch.cat([lstm_out,f2])\n        out = self.dropout(lstm_out)\n        \n        out = self.fc(out)\n        out = self.sigmoid(out)\n        \n        out = out.view(batch_size, -1)\n        out = out[:,-1]\n        return out, hidden\n\n    def init_hidden(self, batch_size):\n        weight = next(self.parameters()).data\n        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n        return hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = vocab_length + 1\noutput_size = 1\nembedding_dim = 400\nhidden_dim = 512\nn_layers = 2\n\nmodel = lstm_model(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\nlr=0.005\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":" for inputs1,inputs2, labels in train_loader:\n        print(inputs1.shape)\n        print(inputs2.shape)\n        print(labels.shape)","execution_count":34,"outputs":[{"output_type":"stream","text":"torch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([400, 300])\ntorch.Size([400, 1])\ntorch.Size([400])\ntorch.Size([250, 300])\ntorch.Size([250, 1])\ntorch.Size([250])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score\nimport time\nstart_time=time.time()\nepochs=1000\nfinal_losses=[]\nfor i in range(epochs):\n    i=i+1\n    for i in range(epochs):\n        hidden = model.init_hidden(batch_size)\n    \n        for inputs1,inputs2, labels in train_loader:\n            y_pred=model.forward(inputs1,inputs2,hidden)\n            loss=loss_function(y_pred,y_train)\n            final_losses.append(loss)\n            if i%10==1:\n                print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n            otimizer.zero_grad()\n            loss.backward()\n            otimizer.step()\nprint(time.time()-start_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## loss function\nimport matplotlib.pyplot as plt\n\nplt.plot(range(epochs),final_losses)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\n#### Prediction in X_test data\npredictions=[]\nwith torch.no_grad():\n    hidden = model.init_hidden(batch_size)\n    for inputs1,inputs2, labels in val_loader:\n        y_pred=model(inputs1,inputs2,hidden)\n        predictions.append(y_pred.argmax().item())\n        print(y_pred.argmax().item())\n\nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,predictions)\ncm\nplt.figure(figsize=(10,6))\nsns.heatmap(cm,annot=True)\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,predictions)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\nrecall_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\nprecision_score(y_test,predictions)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}